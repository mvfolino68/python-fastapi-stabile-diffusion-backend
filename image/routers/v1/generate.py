from fastapi import APIRouter
from fastapi.encoders import jsonable_encoder
from starlette.status import HTTP_201_CREATED

from image import config
from image.routers.exceptions import NotFoundHTTPException
from image.schemas.models import Document, DocumentResponse, ObjectIdField, PipelineData
from image.services.repository import create_document, retrieve_document

import base64
import os
from io import BytesIO

from fastapi import FastAPI, Request, Response, status, Depends
from diffusers import StableDiffusionPipeline
import torch


global_settings = config.get_settings()
collection = global_settings.collection

router = APIRouter()

# Set up diffusion pipeline
HUGGINGFACE_TOKEN = global_settings.huggingface_api_key
model_id = "runwayml/stable-diffusion-v1-5"
device = "cpu"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    # revision="fp16",
    # torch_dtype=torch.float16,
    use_auth_token=HUGGINGFACE_TOKEN,
    custom_pipeline="lpw_stable_diffusion",
)

if torch.cuda.is_available():
    device = "cuda"
    pipe = pipe.to("device")
    pipe.enable_xformers_memory_efficient_attention()

@router.post(
    "",
    status_code=HTTP_201_CREATED,
    response_description="Document created",
    response_model=DocumentResponse,
)
async def add_document(payload: Document):
    """

    :param payload:
    :return:
    """
    try:
        payload = jsonable_encoder(payload)
        return await create_document(payload, collection)
    except ValueError as exception:
        raise NotFoundHTTPException(msg=str(exception))

# cannot have two get functions for same endpoint
# @router.get(
#     "/{object_id}",
#     response_description="Document retrieved",
#     response_model=DocumentResponse,
# )
# async def get_document(object_id: ObjectIdField):
#     """

#     :param object_id:
#     :return:
#     """
#     try:
#         return await retrieve_document(object_id, collection)
#     except ValueError as exception:
#         raise NotFoundHTTPException(msg=str(exception))


# TODO: PUT for replace aka set PATCH for update ?

@router.get(
    "/generate-image",
    # Set what the media type will be in the autogenerated OpenAPI specification.
    # fastapi.tiangolo.com/advanced/additional-responses/#additional-media-types-for-the-main-response
    responses={200: {"content": {"image/png": {}}}},
    # Prevent FastAPI from adding "application/json" as an additional
    # response media type in the autogenerated OpenAPI specification.
    # https://github.com/tiangolo/fastapi/issues/3258
    response_class=Response
)
async def generate(request: Request, pipeline_data: PipelineData = Depends()):
    """
    Get an image from the diffusion pipeline
    """

    try:
        prompt = pipeline_data.prompt
        num_inference_steps = pipeline_data.num_inference_steps
        negative_prompt = pipeline_data.negative_prompt
        image = pipe(
            prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=int(num_inference_steps),
            guidance_scale=8.5,
        ).images[0]
        image.save("testimage.png")
        buffer = BytesIO()
        image.save(buffer, format="PNG")
        imgstr = base64.b64encode(buffer.getvalue())

        # add_document(payload=pipeline_data)

        return Response(content=imgstr, media_type="image/png")
    except Exception as e:
        print(e)
